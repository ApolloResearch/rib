exp_name: pythia-14m
seed: 0
tlens_pretrained: pythia-14m
tlens_model_path: null
dataset:
  name: wikitext
  tokenizer_name: EleutherAI/pythia-14m
  return_set: train
  return_set_frac: 0.1
  return_set_n_samples: null
node_layers:
  - ln1.1
  - mlp_out.1
  - ln1.3
  - ln2.3
  - mlp_out.3
  - ln1.5
  - mlp_out.5
batch_size: 8
truncation_threshold: 1e-6
logits_node_layer: true
rotate_final_node_layer: false
n_intervals: 0
dtype: float32
calculate_edges: false
eval_type: null