exp_name: rib_pythia-14m
ablation_type: rib
interaction_graph_path: /mnt/ssd-apollo/dan/RIB/rib/experiments/lm_rib_build/out/pythia-14m_rib_Cs.pt
schedule:
  schedule_type: linear
  early_stopping_threshold: 1.5
  n_points: 20
dataset:
  source: huggingface
  name: NeelNanda/pile-10k
  tokenizer_name: EleutherAI/pythia-14m
  return_set: train  # pile-10k only has train, so we take the first 90% for building and last 10% for ablations
  return_set_frac: 0.01
  return_set_n_samples: null
  return_set_portion: last
node_layers:
  - mlp_out.0
  - ln2.3
  - mlp_out.3
  - ln1.5
  - mlp_out.5
logits_node_layer: true
batch_size: 30  # A100 can handle 60
dtype: float32
eval_type: ce_loss
seed: 0
