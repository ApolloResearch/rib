exp_name: fire-play-pythia-14m
seed: 0
tlens_pretrained: pythia-14m
tlens_model_path: null
interaction_matrices_path: null
dataset:
  source: huggingface
  name: NeelNanda/pile-10k
  tokenizer_name: EleutherAI/pythia-14m
  return_set: train  # pile-10k only has train, so we take the first 90% for building and last 10% for ablations
  return_set_frac: null
  return_set_n_samples: 20
  return_set_portion: first
node_layers:
  - mlp_in.5
  - add_resid2.5
batch_size: 8  #  A100 can handle 24
gram_batch_size: 20  #  A100 can handle 80
edge_batch_size: 8
truncation_threshold: 1e-6
rotate_final_node_layer: true
n_intervals: 5
dtype: float32
calculate_edges: true
eval_type: null