seed: 0
model:
  n_layers: 1
  d_model: 128
  d_head: 32
  n_heads: 4
  d_mlp: 512
  d_vocab: 114  # modulus + 1
  n_ctx: 3
  act_fn: relu
  normalization_type: null
train:
  modulus: 113  # 'p' in the paper and code
  frac_train: .25
  fn_name: add
  learning_rate: 0.001
  batch_size: 10000
  epochs: 60000
  eval_every_n_epochs: 1000
  save_dir: /mnt/ssd-apollo/checkpoints/rib/modular_arthimetic/
  save_every_n_epochs: 20000
wandb:
  project: transformer-modular-arithmetic
  entity: null
