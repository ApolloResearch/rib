exp_name: tinystories
seed: 0
tlens_pretrained: tiny-stories-1M
tlens_model_path: null
dataset:
  dataset_type: huggingface
  name: roneneldan/TinyStories # or skeskinen/TinyStories-GPT4, but not clear if part of training
  tokenizer_name: EleutherAI/gpt-neo-125M
  return_set: train
  return_set_frac: null
  return_set_n_samples: 50 # avg ~235 toks / story
  return_set_portion: first
  n_ctx: 50 # needs to be <= 511 for the model to behave reasonably
node_layers:
  - ln1.4
  - mlp_out.4
  - ln1.7
  - mlp_out.7
rotate_final_node_layer: true
eval_type: ce_loss
gram_batch_size: 100
batch_size: 50
edge_batch_size: 500
calculate_edges: true
truncation_threshold: 1e-15
dtype: float64
n_intervals: 0
basis_formula: jacobian
edge_formula: squared
n_stochastic_sources_basis_pos: null
n_stochastic_sources_basis_hidden: null
n_stochastic_sources_edges: null
