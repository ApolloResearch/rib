{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#add modular_dnn to path\n",
    "import sys\n",
    "sys.path.append('/mnt/ssd-apollo/jake/rib/experiments/counterexamples')\n",
    "from modular_dnn import BlockDiagonalDNN, RandomVectorDataset\n",
    "from matplotlib import pyplot as plt\n",
    "from rib.hook_manager import HookedModel, Hook\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from rib.hook_fns import acts_pre_forward_hook_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .modular_dnn import BlockDiagonalDNN, RandomVectorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = torch.load('/mnt/ssd-apollo/jake/rib/experiments/counterexamples/results/small_modular_dnn_seed100_n20_k10_layers4_random_act_relu_dsize_1000_bias0/rib_graph.pt')\n",
    "results2 = torch.load('/mnt/ssd-apollo/jake/rib/experiments/counterexamples/results/small_modular_dnn_seed100_n20_k10_layers4_random_act_relu_dsize_1000_bias0_final_layer_fixed/rib_graph.pt')\n",
    "results1.keys()\n",
    "plt.loglog(results1['rib_edges']['squared'][2][1].flatten(),results2['rib_edges']['squared'][2][1].flatten(), '.')\n",
    "plt.title('ratio of edges with and without final layer rotated, newest commit, squared mode')\n",
    "# plt.plot([results1['rib_edges']['squared'][2][1].min(), results1['rib_edges']['squared'][2][1].max()],[results1['rib_edges']['squared'][2][1].min(), results1['rib_edges']['squared'][2][1].max()],'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results['rib_edges'][2][1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['model_config_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results['gram_matrices']['output'].abs().log())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results['gram_matrices']['layers.0'].abs().log())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,S,V = torch.svd(results['gram_matrices']['layers.0'])\n",
    "plt.imshow(U)\n",
    "plt.show()\n",
    "plt.imshow(V/U)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = results['model_config_dict']['n']\n",
    "k = results['model_config_dict']['k']\n",
    "layers = results['model_config_dict']['layers']\n",
    "mlp = BlockDiagonalDNN(layers = layers, n = n, k = k)\n",
    "hooked_mlp = HookedModel(mlp)\n",
    "mlp.load_state_dict(results['mlp'])\n",
    "dataset = RandomVectorDataset(n, k, results['model_config_dict']['dataset_size'],results['model_config_dict']['data_variances'], dtype=results['model_config_dict']['dtype'])\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=results['model_config_dict']['dataset_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnesDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        self.data = torch.ones(n)\n",
    "        self.label = torch.tensor(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1  # Since there's only one datapoint\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data, self.label\n",
    "\n",
    "class IdentityDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        self.data = torch.eye(n)\n",
    "        self.label = torch.tensor(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1  # Since there's only one datapoint\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data, self.label\n",
    "\n",
    "\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "# dataset = OnesDataset(n)\n",
    "# dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IdentityDataset(n)\n",
    "dataloader = DataLoader(dataset, batch_size=n)\n",
    "for data,_ in dataloader:\n",
    "    print(data) \n",
    "    print(mlp(data))\n",
    "    print(hooked_mlp(data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_hook = [f'layers.{i}' for i in range(4)]\n",
    "activation_hooks = []\n",
    "for layer in layers_to_hook:\n",
    "    activation_hooks.append(\n",
    "        Hook(\n",
    "            name=layer, \n",
    "            data_key=\"activations\", \n",
    "            fn=acts_pre_forward_hook_fn, \n",
    "            module_name=layer,\n",
    "            fn_kwargs={}\n",
    "        )\n",
    "    )\n",
    "for inputs, _ in dataloader:\n",
    "    _ = hooked_mlp(inputs, hooks=activation_hooks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "for layer in layers_to_hook:\n",
    "    activations[layer] = hooked_mlp.hooked_data[layer]['activations'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations['layers.0'].std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results['eigenvectors'][0]['U'].abs().log())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results['pca_edges'][0][1].abs().log())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results['interaction_rotations'][1]['C'].abs().log())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    U,S,Vt = torch.svd(activations[f'layers.{i}'])# - activations[f'layers.{i}'].mean(dim=0))\n",
    "    print(S)\n",
    "    plt.scatter(range(len(S)),S.log())\n",
    "    plt.show()\n",
    "    plt.imshow(Vt.abs().log())\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rib-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
